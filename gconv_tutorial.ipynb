{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GConv Module Tutorial\n",
    "\n",
    "The `gconv` module is a Pytorch extension that implements regular group convolution. The provided group convolution layers are as straightforward to use as regular Pytorch convolution layers, requiring no expert knowledge to be used effectively. At the same time, `gconv` offers a flexible framefork for working with group convolutions that is fully custamizable. Both 2D and 3D inputs are supported, as well as discrete group convolutions and approximating continuous groups.\n",
    "\n",
    "This tutorial demonstrates how to get started with the `gconv` module, and how to module can be used to implement custom group convolutions.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "The `gconv` modules are as straightforward to use as any regular Pytorch convolution module. The only difference is the output consisting of both the feature maps, as well as the group elements on which they are defined. See the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thijs/miniconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/functional.py:4215: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch                                                                        \n",
    "import gconv.nn as gnn                                                              \n",
    "\n",
    "# input batch of 3d data with 3 channels\n",
    "x1 = torch.randn(1, 3, 28, 28, 28)\n",
    "\n",
    "# the lifting layer is required to lift R3 input to the group\n",
    "lifting_layer = gnn.GLiftingConvSE3(in_channels=3, out_channels=16, kernel_size=5)\n",
    "gconv_layer = gnn.GSeparableConvSE3(in_channels=16, out_channels=32, kernel_size=5)\n",
    "\n",
    "# global avg pooling to produce invariant features after the group convolutions\n",
    "pool = gnn.GAvgGlobalPool()\n",
    "\n",
    "# gconv modules return the feature maps and the group elements on which they are defined\n",
    "x2, H1 = lifting_layer(x1)\n",
    "x3, H2 = gconv_layer(x2, H1)\n",
    "\n",
    "y = pool(x3, H2)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a custom group convolution\n",
    "\n",
    "This section explains how to implement a custom group convolutions. Group convolutions consists of (1) a `GroupKernel` module that manages the weight and performs all group related actions and (2) a `GroupConv` module that samples the kernel and performs the convolution. In this example, we will create a lifting and a separable group convolution module for 2D rotations, i.e., the SE(2) group. We start with implementing the lifting and separable kernels.\n",
    "\n",
    "### Implementing the SE(2) kernels\n",
    "\n",
    "All that is required for implementing a custom kernel is the logic that deals with the group elements. For this, the following callable objects should be implemented for the given group `H`:\n",
    "\n",
    "* `det_H(H: Tensor) -> Tensor`: accepts a tensor of group elements and returns their determinants.\n",
    "* `inverse_H(H: Tensor) -> Tensor`: accepts a tensor of group elements and returns their inverses.\n",
    "* `left_apply_H_to_H(H1: Tensor, H2: Tensor) -> Tensor`: accepts tensors of group elements `H1` of shape `(N, ...)` and `H2` of shape `(M, ...)` and returns the pairwise left group action resulting in a tensor of shape `(N, M, ...)`.\n",
    "* `left_apply_H_to_Rn(H: Tensor, grid: Tensor) -> Tensor`: accepts a tensor of group elements `H` of shape `(N, *dims)` and a tensor of Rn vectors of shape `(..., Rn)` and calculates the pairwise product between H and grid, resulting in a tensor of shape `(N, ..., Rn)`.\n",
    "* `grid_sample(grid: Tensor, signal: Tensor, signal_grid: Tensor) -> Tensor`: Given a tensor `signal` of shape `(N, S)` and a corresponding tensor `signal_grid` of group elements of shape `(N, *dims)`, samples the signal for given `grid` tensor of group elements of shape `(M. *dims)`. The returned signal is a tensor of shape `(M, S)`.\n",
    "\n",
    "We will implement these methods for the SO(2) group below. For this, we need to chose a representation for the group elements. In the case of SO(2), a simple representation is simply the angle of the rotation. Hence, our SO(2) elements are in the range of [0, $2\\pi$)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we implement the above methods, we first introduce two methods that allow us to sample SO2 elements: `uniform_grid_so2(n: int) -> Tensor` which given an integer `n` generates a uniform grid on so2 of `n` elements, and `random_grid_so2(n: int) -> Tensor` which generates an `n` size grid of randomly sampled SO2 elements. We also implement a function that samples a uniform grid on R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.7662],\n",
      "        [4.7929],\n",
      "        [1.7150],\n",
      "        [1.1299],\n",
      "        [3.2560],\n",
      "        [0.8922],\n",
      "        [4.4672],\n",
      "        [1.4345]])\n",
      "torch.Size([5, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from torch import Tensor\n",
    "\n",
    "def uniform_grid_so2(n: int, device: str | None = None) -> Tensor:\n",
    "    return torch.linspace(0, 2 * math.pi, n + 1, device=device)[:-1].view(-1, 1)\n",
    "\n",
    "def random_grid_so2(n: int, device: str | None = None) -> Tensor:\n",
    "    return 2 * math.pi * torch.rand(n, device=device).view(-1, 1)\n",
    "\n",
    "def create_grid_R2(n: int, device: str | None = None) -> Tensor:\n",
    "    x = torch.linspace(-1, 1, n, device=device)\n",
    "    X, Y = torch.meshgrid((x, x), indexing=\"xy\")\n",
    "    \n",
    "    return torch.stack((Y, X), dim=-1)\n",
    "\n",
    "grid = random_grid_so2(8)\n",
    "\n",
    "print(grid)\n",
    "\n",
    "grid_R2 = create_grid_R2(5)\n",
    "\n",
    "print(grid_R2.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the group determinant\n",
    "\n",
    "The determinant of any rotation is simply 1, which is the default for the `GroupKernel`, so we do not need to implement it. Here, we will do so anyway for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "def det_so2(H: Tensor) -> Tensor:\n",
    "    return torch.ones_like(H)\n",
    "\n",
    "print(det_so2(grid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the group inverse\n",
    "\n",
    "The inverse of a rotation $\\theta$ is simply a rotation by $-\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.7662],\n",
      "        [-4.7929],\n",
      "        [-1.7150],\n",
      "        [-1.1299],\n",
      "        [-3.2560],\n",
      "        [-0.8922],\n",
      "        [-4.4672],\n",
      "        [-1.4345]])\n"
     ]
    }
   ],
   "source": [
    "def inverse_so2(H: Tensor) -> Tensor:\n",
    "    return -H\n",
    "\n",
    "print(inverse_so2(grid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the left group action\n",
    "\n",
    "If we rotate by $\\theta_1$ to which we then left-apply $\\theta_2$, we obtain the new rotation $(\\theta_1 + \\theta_2) \\mod 2\\pi$. The modulo operation is required to keep the group elements in the defined interval of [0, $2\\pi$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8, 1])\n"
     ]
    }
   ],
   "source": [
    "def left_apply_to_so2(H1: Tensor, H2: Tensor) -> Tensor:\n",
    "    # broadcast to apply every element in H1 to every element in H2\n",
    "    return (H1[:, None] + H2) % (2 * math.pi)\n",
    "\n",
    "print(left_apply_to_so2(grid, grid).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the left group action on R2.\n",
    "\n",
    "The spatial grid on which the weights are defined are of shape `(W, H, 2)` in the 2D case, where `W` and `H` are the width and height of the kernels, respectively. Each element of the spatial grid denotes the x and position. 2D vectors can simply be rotated by a rotation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 5, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "def left_apply_to_R2(H: Tensor, grid: Tensor) -> Tensor:\n",
    "    matrices = H.new_empty(H.shape[0], 2, 2)\n",
    "\n",
    "    cos_H = torch.cos(H).flatten(-2)\n",
    "    sin_H = torch.sin(H).flatten(-2)\n",
    "\n",
    "    matrices[..., 0, 0] = cos_H\n",
    "    matrices[..., 0, 1] = -sin_H\n",
    "    matrices[..., 1, 0] = sin_H\n",
    "    matrices[..., 1, 1] = cos_H\n",
    "\n",
    "    # broadcast to apply every matrix in matrices to every 2d vector in grid\n",
    "    return (matrices[:, None, None] @ grid[..., None]).flatten(-2)\n",
    "\n",
    "print(left_apply_to_R2(grid, grid_R2).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing grid sampling for SO2\n",
    "\n",
    "The group kernels are represented by a discretization of the group. In the case for SO2, this could be some number of rotations with corresponding weights.\n",
    "\n",
    "To approximate the full continuous SO2 group, we are required to sample the weights of any SO2 element. Therefore, we use the discretization as a basis of a continuous signal defined over SO2 through interpolation.\n",
    "\n",
    "Given a uniform discrete SO2 grid, we can view this grid as points on the unit circle. Hence, we can find the signal of any SO2 element by finding the two neighbouring points and linearly interpolating between them. This can simply be done by transforming our group elements to carthesian coordinates (x, y vectors) that represent points on the unit sphere. The distance between points is then simply the angle between the vectors. This representation has the benefit of dealing with the periodicity of the SO2 manifold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64])\n"
     ]
    }
   ],
   "source": [
    "def grid_sample_so2(grid: Tensor, signal: Tensor, signal_grid: Tensor) -> Tensor:\n",
    "    # transform grid to carthesian coordinates.\n",
    "    grid_cart = grid.new_empty(grid.shape[0], 2)\n",
    "    grid_cart[..., 0] = torch.cos(grid).flatten(-2)\n",
    "    grid_cart[..., 1] = torch.sin(grid).flatten(-2)\n",
    "\n",
    "    # transform signal_grid to carthesian coordinates.\n",
    "    signal_grid_cart = signal_grid.new_empty(signal_grid.shape[0], 2)\n",
    "    signal_grid_cart[..., 0] = torch.cos(signal_grid).flatten(-2)\n",
    "    signal_grid_cart[..., 1] = torch.sin(signal_grid).flatten(-2)\n",
    "\n",
    "    # we calculate the distance of all points in grid to\n",
    "    # all points in the signal grid to find the two neighbours,\n",
    "    # i.e., the two closest points. In the case vectors on the unit\n",
    "    # sphere, this is simply the dot product between them\n",
    "    distances = (grid_cart[:, None] * signal_grid_cart).sum(-1)\n",
    "\n",
    "    # obtain the two neighbours and the distances to them\n",
    "    dists, neighbours = torch.topk(distances, 2, largest=False)\n",
    "\n",
    "    # to obtain the interpolation coefficients, we need to normalize\n",
    "    # the distances, such that the distances between two neighbours equals\n",
    "    # 1. Given a uniform grid of N rotations, we divide by (2pi / N).\n",
    "    coeffs = dists / ((2 * math.pi) / signal_grid.shape[0])\n",
    "\n",
    "    # now we can perform the linear interpolation and return the new signal\n",
    "    return (coeffs[..., None] * signal[neighbours]).sum(-2)\n",
    "\n",
    "# we define a signal on uniform 4 element grid\n",
    "signal = torch.randn(4, 64)\n",
    "signal_grid = uniform_grid_so2(4)\n",
    "\n",
    "print(grid_sample_so2(grid, signal, signal_grid).shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the lifting kernel\n",
    "\n",
    "Now we have all the necessary components to start building the kernels. We first create a SE2 lifting kernel module. For this, we create a new class that inhererits from `gconv.nn.kernels.GLiftingKernel`. For interpolating spatial kernels, we can simply utilize the `grid_sample` function `torch.nn.functional`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "from gconv.nn.kernels import GLiftingKernel\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class GLiftingKernelSE2(GLiftingKernel):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            kernel_size: int,\n",
    "            group_kernel_size: int,\n",
    "            groups: int = 1,\n",
    "        ) -> None:\n",
    "\n",
    "        # we initiaize the kernel grids used for sampling here.\n",
    "        grid_H = uniform_grid_so2(group_kernel_size)\n",
    "        grid_Rn = create_grid_R2(kernel_size)\n",
    "\n",
    "        # We can also pass any kwargs to the sample function.\n",
    "        # In our case, we use F.grid_sample, which we can give an \n",
    "        # interpolation mode, for which we use \"bilinear\" and a\n",
    "        # padidng mode, for which we use \"border\".\n",
    "        sample_Rn_kwargs = {\"mode\": \"bilinear\", \"padding_mode\": \"border\"}\n",
    "        \n",
    "        super().__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            (kernel_size, kernel_size), # kernel sizes are tupels\n",
    "            (group_kernel_size,), # same for group kernel size\n",
    "            grid_H,\n",
    "            grid_Rn,\n",
    "            groups,\n",
    "            det_H=det_so2,\n",
    "            inverse_H=inverse_so2,\n",
    "            left_apply_to_Rn=left_apply_to_R2,\n",
    "            sample_Rn=F.grid_sample,\n",
    "            sample_Rn_kwargs=sample_Rn_kwargs,\n",
    "        )\n",
    "\n",
    "in_channels = 3\n",
    "out_channels = 16\n",
    "kernel_size = 5\n",
    "group_kernel_size = 8\n",
    "\n",
    "lifting_kernel = GLiftingKernelSE2(in_channels, out_channels, kernel_size, group_kernel_size)\n",
    "weight = lifting_kernel(grid)\n",
    "\n",
    "# should be (out_channels, group_kernel_size, in_channels, kernel_size, kernel_size)\n",
    "print(weight.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the Separable Kernel\n",
    "\n",
    "Next we implement the separable SE2 kernel, which inherits from `gconv.nn.kernels.GSeparableKernel`. We will see that the kernel initialization is the same as the lifting kernel, apart from also initializing the group on group actions and sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8, 3, 8, 1, 1])\n",
      "torch.Size([16, 8, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "from gconv.nn.kernels import GSeparableKernel\n",
    "\n",
    "class GSeparableKernelSE2(GSeparableKernel):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            kernel_size: int,\n",
    "            group_kernel_size: int,\n",
    "            groups: int = 1,\n",
    "        ) -> None:\n",
    "\n",
    "        # we initiaize the kernel grids used for sampling here.\n",
    "        grid_H = uniform_grid_so2(group_kernel_size)\n",
    "        grid_Rn = create_grid_R2(kernel_size)\n",
    "\n",
    "        # we again use F.grid_sample. Our sampling of SO2 does not require\n",
    "        # any extra kwargs\n",
    "        sample_Rn_kwargs = {\"mode\": \"bilinear\", \"padding_mode\": \"border\"}\n",
    "        \n",
    "        super().__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            (kernel_size, kernel_size), # kernel sizes are tupels\n",
    "            (group_kernel_size,), # same for group kernel size\n",
    "            grid_H,\n",
    "            grid_Rn,\n",
    "            groups,\n",
    "            det_H=det_so2,\n",
    "            inverse_H=inverse_so2,\n",
    "            left_apply_to_H=left_apply_to_so2,\n",
    "            left_apply_to_Rn=left_apply_to_R2,\n",
    "            sample_H=grid_sample_so2,\n",
    "            sample_Rn=F.grid_sample,\n",
    "            sample_Rn_kwargs=sample_Rn_kwargs,\n",
    "        )\n",
    "\n",
    "in_channels = 3\n",
    "out_channels = 16\n",
    "kernel_size = 5\n",
    "group_kernel_size = 8\n",
    "\n",
    "separable_kernel = GSeparableKernelSE2(in_channels, out_channels, kernel_size, group_kernel_size)\n",
    "\n",
    "grid_in = grid\n",
    "grid_out = grid\n",
    "\n",
    "# separate weights for the subrgoup (H) and spatial (Rn) parts\n",
    "weight_H, weight_Rn = separable_kernel(grid, grid)\n",
    "\n",
    "# should be (out_channels, len(grid_in), in_channels, len(grid_out), 1, 1)\n",
    "print(weight_H.shape)\n",
    "\n",
    "# should be (out_channels, len(grid_out), 1, kernel_size, kernel_size)\n",
    "print(weight_Rn.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the lifting and separable convolution modules\n",
    "\n",
    "Now that we have implemented the lifting and separable group kernels, we can initialize the group convolution modules. We again start with the lifting convolution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the lifting convolution module\n",
    "\n",
    "Since we are working with SE(2), our SE(2) lifting convolution module inherits from `gconv.nn.GLiftingConv2d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/thijs/Documents/KI/master/thesis/gconv/gconv_tutorial.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/thijs/Documents/KI/master/thesis/gconv/gconv_tutorial.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39musers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mthijs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocuments\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mki\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmaster\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mthesis\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgconv\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgconv\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkernels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__init__\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpy\u001b[39;00m \u001b[39mimport\u001b[39;00m GLiftingKernel\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thijs/Documents/KI/master/thesis/gconv/gconv_tutorial.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgconv\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mimport\u001b[39;00m GLiftingConv2d\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thijs/Documents/KI/master/thesis/gconv/gconv_tutorial.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mGLiftingConvSE2\u001b[39;00m(GLiftingConv2d):\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from gconv.nn import GLiftingConv2d\n",
    "\n",
    "class GLiftingConvSE2(GLiftingConv2d):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            kernel_size: int,\n",
    "            group_kernel_size: int,\n",
    "            groups: int = 1,\n",
    "            stride: int = 1,\n",
    "            padding: int | str = 0,\n",
    "            dilation: int = 1,\n",
    "            padding_mode: str = \"zeros\",\n",
    "            bias: bool = False) -> None:\n",
    "        \n",
    "        # all we need to do is intialize the kernel and pass it\n",
    "        # to the super call\n",
    "        kernel = GLiftingKernelSE2(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            group_kernel_size,\n",
    "            groups=groups\n",
    "        )\n",
    "\n",
    "        super().__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            group_kernel_size,\n",
    "            kernel,\n",
    "            groups,\n",
    "            stride,\n",
    "            padding,\n",
    "            dilation,\n",
    "            padding_mode,\n",
    "            bias\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
